{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "daa604d8-3c27-4340-8d33-ce8d623bfda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from keras_facenet import FaceNet\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mtcnn\n",
    "import mediapipe as mp\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "from collections import Counter\n",
    "import uuid\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f32852ff-4635-4b1b-b365-fabe1e0bb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the ml models that are used for the creation of the system\n",
    "Haarcascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "Facenet=FaceNet()\n",
    "eyecascade=cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1abfc57a-4fbe-4ec3-8978-dd61491dd101",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type function is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mFacenet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfcnet.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type function is not JSON serializable"
     ]
    }
   ],
   "source": [
    "Facenet.model.save(\"fcnet.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "217de907-e3e3-4b0b-985f-f3a7af99c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model= Facenet.model\n",
    "\n",
    "x=tf.keras.layers.Input(shape=(160,160,3))\n",
    "y=f_model(x)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "new_model=Model(inputs=[x],outputs=[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb4f4770-496f-4fe4-892d-c58660b321d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8eitw0kk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8eitw0kk/assets\n",
      "2023-11-27 20:34:00.912961: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-27 20:34:00.913002: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-27 20:34:00.913773: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp8eitw0kk\n",
      "2023-11-27 20:34:00.959292: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-27 20:34:00.959361: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp8eitw0kk\n",
      "2023-11-27 20:34:01.034792: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2023-11-27 20:34:01.093216: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-27 20:34:02.127146: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp8eitw0kk\n",
      "2023-11-27 20:34:02.502176: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 1588403 microseconds.\n",
      "2023-11-27 20:34:02.925576: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 267, Total Ops 452, % non-converted = 59.07 %\n",
      " * 267 ARITH ops\n",
      "\n",
      "- arith.constant:  267 occurrences  (f32: 266, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 21)\n",
      "  (f32: 23)\n",
      "  (f32: 132)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open('Facenet.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "375bec0c-5af0-4ace-ab24-3b8f01b80850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphjr2mbw3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphjr2mbw3/assets\n",
      "2023-11-27 21:43:47.448001: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-27 21:43:47.448072: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-27 21:43:47.449003: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmphjr2mbw3\n",
      "2023-11-27 21:43:47.504267: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-27 21:43:47.504429: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmphjr2mbw3\n",
      "2023-11-27 21:43:47.615030: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2023-11-27 21:43:47.716140: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-27 21:43:49.065532: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmphjr2mbw3\n",
      "2023-11-27 21:43:49.587060: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 2138056 microseconds.\n",
      "2023-11-27 21:43:50.198570: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 135, Total Ops 452, % non-converted = 29.87 %\n",
      " * 135 ARITH ops\n",
      "\n",
      "- arith.constant:  135 occurrences  (f32: 134, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 21)\n",
      "  (f32: 23)\n",
      "  (f32: 132)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "  (uq_8: 132)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming new_model is your Keras model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n",
    "\n",
    "# Enable post-training quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open('Facenet_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d438344-251e-47f4-9d01-2e5387c410f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05cdf769-e62f-4dd2-8234-483a64fe2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"Facenet_quantized.tflite\")\n",
    "interpreter.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb5b136c-37e5-404d-8bcc-187a56d60d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = tf.random.normal(shape=(1, 160, 160, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e153bfc-24d9-4ca6-b7d0-f45e05cc191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c465d5e-a95e-41a1-ae5c-da2c72db2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d870453-4912-4769-8cb1-5f63cb79d622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "211058a5-ed26-4855-ae2a-0a49ba6576c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1be69e85-8f85-4829-8d09-b0f5576e04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(tensor):\n",
    "    input_tensor_index = interpreter.get_input_details()[0]['index']\n",
    "    interpreter.tensor(input_tensor_index)()[0] = tensor\n",
    "    interpreter.invoke()\n",
    "    output_tensor_index = interpreter.get_output_details()[0]['index']\n",
    "    output_data = interpreter.tensor(output_tensor_index)()\n",
    "    return np.array(output_data)  # Convert to NumPy array before returning\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db209a0c-7652-49fc-b11c-1067dbaf23c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " inception_resnet_v1 (Funct  (None, 512)               23497424  \n",
      " ional)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23497424 (89.64 MB)\n",
      "Trainable params: 23467824 (89.52 MB)\n",
      "Non-trainable params: 29600 (115.62 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f7aa677-a904-4143-a132-2d0856df82d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is  a class that is used for various datamanupulation in our database folder \n",
    "class database_man():\n",
    "    def __init__(self,threshold,database_path):\n",
    "        self.threshold=threshold\n",
    "        self.database_path=database_path\n",
    "        self.list_of_people=os.listdir(self.database_path)\n",
    "        \n",
    "    def return_name_max(self,embedding):\n",
    "        confidence_list=[]\n",
    "        for i in self.list_of_people:\n",
    "            temp_np=np.load(f\"{self.database_path}/{i}\")\n",
    "            confidence_list.append(np.linalg.norm(embedding-temp_np))\n",
    "        Most_sim=min(confidence_list)\n",
    "        print(Most_sim)\n",
    "        return Most_sim,os.path.splitext(self.list_of_people[confidence_list.index(Most_sim)])[0]\n",
    "    def create_numpy(self,name,image_path):\n",
    "        embedding=get_embeddings(image_path)\n",
    "        path=f\"{self.database_path}/{name}\"\n",
    "        np.save(path,embedding)\n",
    "    def create_numpy_frame(self,embedding,name):\n",
    "        path=f\"{self.database_path}/{name}\"\n",
    "        np.save(path,embedding)\n",
    "    def Create_cluster_data(self,name,embedding):\n",
    "        try:\n",
    "            os.makedirs(f\"{self.database_path}/{name}\")\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            return None\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        for i in range(25):\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "        \n",
    "            # Get embeddings using the defined function\n",
    "            embeddings = self.get_embeddings_frame(frame)\n",
    "            time.sleep(2)\n",
    "            if(embeddings is not None):\n",
    "                #print(database.return_name_max(embeddings))\n",
    "                print(\"saving\")\n",
    "                file_name=f\"{self.database_path}/{name}/{str(uuid.uuid4())}.npy\"\n",
    "                np.save(file_name,embeddings)\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "            cv2.imshow('Frame', frame)\n",
    "        \n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbae4866-86d8-418e-847f-8156bc359c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "database=database_man(0.8,\"DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03cdcb62-c4da-4651-932a-a9ae1b31ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this fuction takes an image path detects face and eyes of the image rotate crops the face, then rotate the croped image such that the eyes \n",
    "#the face is alligned straight\n",
    "def get_embeddings(path):\n",
    "    with mp_face_detection.FaceDetection(\n",
    "            model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image)\n",
    "        \n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, _ = image.shape\n",
    "                x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                \n",
    "                cropedimage = image[y:y+h, x:x+w]\n",
    "                \n",
    "                cropimg = cv2.resize(copy.deepcopy(cropedimage), (160, 160))\n",
    "                eyes = eyecascade.detectMultiScale(cropimg, 1.1, 4)\n",
    "\n",
    "                if len(eyes) >= 2:\n",
    "                    eye1 = eyes[0]\n",
    "                    eye2 = eyes[1]\n",
    "\n",
    "                    left_eye_center = (int(eye1[0] + (eye1[2] / 2)), int(eye1[1] + (eye1[3] / 2)))\n",
    "                    right_eye_center = (int(eye2[0] + (eye2[2] / 2)), int(eye2[1] + (eye2[3] / 2)))\n",
    "\n",
    "                    \n",
    "                    angle = np.arctan2(right_eye_center[1] - left_eye_center[1], right_eye_center[0] - left_eye_center[0]) * 180 / np.pi\n",
    "\n",
    "                   \n",
    "                    eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2, (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "\n",
    "                    \n",
    "                    M = cv2.getRotationMatrix2D(eyes_center, angle, 1.0)\n",
    "\n",
    "                    \n",
    "                    rotated = cv2.warpAffine(cropimg, M, (160, 160))\n",
    "\n",
    "                    cropimg_tens = np.expand_dims(rotated, axis=0)\n",
    "                    embeddings = Facenet.embeddings(cropimg_tens)\n",
    "                    '''print(embeddings)\n",
    "                    plt.imshow(rotated)  \n",
    "                    plt.show()  '''\n",
    "                \n",
    "                    return embeddings\n",
    "                else:\n",
    "                    \n",
    "                    print(\"Not enough eyes detected for rotation.\")\n",
    "                    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbead0b-69ab-421e-870e-0b69a59a878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same function but takes frames as input\n",
    "def get_embeddings_frame(frame):\n",
    "    with mp_face_detection.FaceDetection(\n",
    "            model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "        image = frame\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image)\n",
    "        \n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, _ = image.shape\n",
    "                x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                \n",
    "                cropedimage = image[y:y+h, x:x+w]\n",
    "                \n",
    "                cropimg = cv2.resize(copy.deepcopy(cropedimage), (160, 160))\n",
    "                eyes = eyecascade.detectMultiScale(cropimg, 1.1, 4)\n",
    "\n",
    "                if len(eyes) >= 2:\n",
    "                    eye1 = eyes[0]\n",
    "                    eye2 = eyes[1]\n",
    "\n",
    "                    left_eye_center = (int(eye1[0] + (eye1[2] / 2)), int(eye1[1] + (eye1[3] / 2)))\n",
    "                    right_eye_center = (int(eye2[0] + (eye2[2] / 2)), int(eye2[1] + (eye2[3] / 2)))\n",
    "\n",
    "                    \n",
    "                    angle = np.arctan2(right_eye_center[1] - left_eye_center[1], right_eye_center[0] - left_eye_center[0]) * 180 / np.pi\n",
    "\n",
    "                   \n",
    "                    eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2, (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "\n",
    "                    \n",
    "                    M = cv2.getRotationMatrix2D(eyes_center, angle, 1.0)\n",
    "\n",
    "                    \n",
    "                    rotated = cv2.warpAffine(cropimg, M, (160, 160))\n",
    "\n",
    "                    cropimg_tens = np.expand_dims(rotated, axis=0)\n",
    "                    embeddings = Facenet.embeddings(cropimg_tens)\n",
    "                    '''print(embeddings)\n",
    "                    plt.imshow(rotated)  \n",
    "                    plt.show()  '''\n",
    "                \n",
    "                    return embeddings\n",
    "                else:\n",
    "                    \n",
    "                    print(\"Not enough eyes detected for rotation.\")\n",
    "                    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f0bf1d-053d-4e99-b169-d7bd4256b298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n"
     ]
    }
   ],
   "source": [
    "#loop for checking attendance\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    conformation_list=[]\n",
    "    for i in range(10):\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "    \n",
    "        # Get embeddings using the defined function\n",
    "        embeddings = get_embeddings_frame(frame)\n",
    "        if(embeddings is not None):\n",
    "            if database.return_name_max(embeddings)[0]<0.7:\n",
    "                conformation_list.append(database.return_name_max(embeddings)[1])\n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "        cv2.imshow('Frame', frame)\n",
    "    if(len(Counter(conformation_list).most_common(1))!=0):\n",
    "        print(Counter(conformation_list).most_common(1)[0])\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "    \n",
    "            \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf5f0fc-3a3f-4077-bb32-ea5ef05bb08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    }
   ],
   "source": [
    "#for saving new images to database\n",
    "name=input(\"Enter your name\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Get embeddings using the defined function\n",
    "    embeddings = get_embeddings_frame(frame)\n",
    "    if(embeddings is not None):\n",
    "        #print(database.return_name_max(embeddings))\n",
    "        database.create_numpy_frame(embeddings,name)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9798e126-ff4e-4bed-ab02-552e7fa53447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionSystem():\n",
    "    def __init__(self,database):\n",
    "        self.Haarcascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "        \n",
    "        self.eyecascade=cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "        self.mp_face_detection = mp.solutions.face_detection\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.database=database\n",
    "    \n",
    "    def get_embeddings(self,path):\n",
    "        with self.mp_face_detection.FaceDetection(\n",
    "                model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "            image = cv2.imread(path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image)\n",
    "            \n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, _ = image.shape\n",
    "                    x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    \n",
    "                    cropedimage = image[y:y+h, x:x+w]\n",
    "                    \n",
    "                    cropimg = cv2.resize(copy.deepcopy(cropedimage), (160, 160))\n",
    "                    eyes = self.eyecascade.detectMultiScale(cropimg, 1.1, 4)\n",
    "    \n",
    "                    if len(eyes) >= 2:\n",
    "                        eye1 = eyes[0]\n",
    "                        eye2 = eyes[1]\n",
    "    \n",
    "                        left_eye_center = (int(eye1[0] + (eye1[2] / 2)), int(eye1[1] + (eye1[3] / 2)))\n",
    "                        right_eye_center = (int(eye2[0] + (eye2[2] / 2)), int(eye2[1] + (eye2[3] / 2)))\n",
    "    \n",
    "                        \n",
    "                        angle = np.arctan2(right_eye_center[1] - left_eye_center[1], right_eye_center[0] - left_eye_center[0]) * 180 / np.pi\n",
    "    \n",
    "                       \n",
    "                        eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2, (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "    \n",
    "                        \n",
    "                        M = cv2.getRotationMatrix2D(eyes_center, angle, 1.0)\n",
    "    \n",
    "                        \n",
    "                        rotated = cv2.warpAffine(cropimg, M, (160, 160))\n",
    "    \n",
    "                        cropimg_tens = np.expand_dims(rotated, axis=0)\n",
    "                        embeddings = get_output(cropimg_tens)\n",
    "                        '''print(embeddings)\n",
    "                        plt.imshow(rotated)  \n",
    "                        plt.show()  '''\n",
    "                    \n",
    "                        return embeddings\n",
    "                    else:\n",
    "                        \n",
    "                        print(\"Not enough eyes detected for rotation.\")\n",
    "                        return None\n",
    "\n",
    "    def get_embeddings_frame(self,frame):\n",
    "        with self.mp_face_detection.FaceDetection(\n",
    "                model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "            image = frame\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image)\n",
    "            \n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, _ = image.shape\n",
    "                    x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    \n",
    "                    cropedimage = image[y:y+h, x:x+w]\n",
    "                    try:\n",
    "                        cropimg = cv2.resize(copy.deepcopy(cropedimage), (160, 160))\n",
    "                        \n",
    "                    \n",
    "                        \n",
    "        \n",
    "                        cropimg_tens = np.expand_dims(cropimg, axis=0)\n",
    "                        embeddings = get_output(cropimg_tens)\n",
    "                        '''print(embeddings)\n",
    "                            plt.imshow(rotated)  \n",
    "                            plt.show()  '''\n",
    "                            \n",
    "                        return embeddings\n",
    "                    except Exception as e:\n",
    "                        \n",
    "                        return None\n",
    "                        \n",
    "                   \n",
    "\n",
    "\n",
    "    def Attendanceloop(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            conformation_list = []\n",
    "            for i in range(10):\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    print(\"Ignoring empty camera frame.\")\n",
    "                    continue\n",
    "                \n",
    "                image = deepcopy(frame)\n",
    "                \n",
    "                \n",
    "                # Get embeddings using the defined function\n",
    "                if self.get_embeddings_frame(frame) is not None:\n",
    "                    embeddings = self.get_embeddings_frame(frame)\n",
    "                    \n",
    "                    if self.database.return_name_max(embeddings)[0] < 0.65:\n",
    "                        conformation_list.append(self.database.return_name_max(embeddings)[1])\n",
    "                \n",
    "                \n",
    "                cv2.imshow('Frame', frame)\n",
    "            \n",
    "            if len(Counter(conformation_list).most_common(1)) != 0:\n",
    "                print(Counter(conformation_list).most_common(1)[0])\n",
    "            \n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    def SavetoDB(self):\n",
    "        name=input(\"Enter your name\")\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "        \n",
    "            # Get embeddings using the defined function\n",
    "            embeddings = self.get_embeddings_frame(frame)\n",
    "            if(embeddings is not None):\n",
    "                #print(database.return_name_max(embeddings))\n",
    "                print(\"saving\")\n",
    "                self.database.create_numpy_frame(embeddings,name)\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "            cv2.imshow('Frame', frame)\n",
    "        \n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8719ab90-c109-41ca-9def-120ddfbdcfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RC=RecognitionSystem(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe7f6b-959f-4e2e-a70a-e5b3576eb844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d82fedab-09d8-4e65-823a-ebf8f7db7490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.11/site-packages/google/protobuf/symbol_database.py:78: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42116347\n",
      "0.42116347\n",
      "0.43159777\n",
      "0.43159777\n",
      "0.424177\n",
      "0.424177\n",
      "0.439663\n",
      "0.439663\n",
      "0.45481372\n",
      "0.45481372\n",
      "0.39965853\n",
      "0.39965853\n",
      "0.31239817\n",
      "0.31239817\n",
      "0.4006431\n",
      "0.4006431\n",
      "0.48961142\n",
      "0.48961142\n",
      "0.455442\n",
      "0.455442\n",
      "('Philip', 10)\n",
      "0.4846478\n",
      "0.4846478\n",
      "0.43485227\n",
      "0.43485227\n",
      "0.36548913\n",
      "0.36548913\n",
      "0.41769633\n",
      "0.41769633\n",
      "0.42673945\n",
      "0.42673945\n",
      "0.43884343\n",
      "0.43884343\n",
      "0.46742272\n",
      "0.46742272\n",
      "0.4849051\n",
      "0.4849051\n",
      "0.46851882\n",
      "0.46851882\n",
      "0.4761696\n",
      "0.4761696\n",
      "('Philip', 10)\n",
      "0.41751003\n",
      "0.41751003\n",
      "0.47799015\n",
      "0.47799015\n",
      "0.4528575\n",
      "0.4528575\n",
      "0.45009857\n",
      "0.45009857\n",
      "0.47292832\n",
      "0.47292832\n",
      "0.5191559\n",
      "0.5191559\n",
      "0.43417075\n",
      "0.43417075\n",
      "0.38857827\n",
      "0.38857827\n",
      "0.36623713\n",
      "0.36623713\n",
      "0.49321344\n",
      "0.49321344\n",
      "('Philip', 10)\n",
      "0.31693977\n",
      "0.31693977\n",
      "0.43903524\n",
      "0.43903524\n",
      "0.5881758\n",
      "0.5881758\n",
      "0.5059471\n",
      "0.5059471\n",
      "0.5240608\n",
      "0.5240608\n",
      "0.58041203\n",
      "0.58041203\n",
      "0.5326158\n",
      "0.5326158\n",
      "0.65349185\n",
      "0.46007723\n",
      "0.46007723\n",
      "0.36058438\n",
      "0.36058438\n",
      "('Philip', 9)\n",
      "0.35928127\n",
      "0.35928127\n",
      "0.37836295\n",
      "0.37836295\n",
      "0.39743108\n",
      "0.39743108\n",
      "0.42684677\n",
      "0.42684677\n",
      "0.4464949\n",
      "0.4464949\n",
      "0.4613331\n",
      "0.4613331\n",
      "0.4632871\n",
      "0.4632871\n",
      "0.51434624\n",
      "0.51434624\n",
      "0.39596745\n",
      "0.39596745\n",
      "0.46209955\n",
      "0.46209955\n",
      "('Philip', 10)\n",
      "0.4773453\n",
      "0.4773453\n",
      "0.46515396\n",
      "0.46515396\n",
      "0.48824787\n",
      "0.48824787\n",
      "0.3992093\n",
      "0.3992093\n",
      "0.467001\n",
      "0.467001\n",
      "0.43079123\n",
      "0.43079123\n",
      "0.33911532\n",
      "0.33911532\n",
      "0.3369218\n",
      "0.3369218\n",
      "0.45924768\n",
      "0.45924768\n",
      "0.26554725\n",
      "0.26554725\n",
      "('Philip', 10)\n",
      "0.36897036\n",
      "0.36897036\n",
      "0.50627345\n",
      "0.50627345\n",
      "0.47790673\n",
      "0.47790673\n",
      "0.35523832\n",
      "0.35523832\n",
      "0.39475447\n",
      "0.39475447\n",
      "0.43725315\n",
      "0.43725315\n",
      "0.49552774\n",
      "0.49552774\n",
      "0.4767926\n",
      "0.4767926\n",
      "0.5338265\n",
      "0.5338265\n",
      "0.503038\n",
      "0.503038\n",
      "('Philip', 10)\n",
      "0.49891332\n",
      "0.49891332\n",
      "0.49542117\n",
      "0.49542117\n",
      "0.42390382\n",
      "0.42390382\n",
      "0.38166556\n",
      "0.38166556\n",
      "0.41229236\n",
      "0.41229236\n",
      "0.5217695\n",
      "0.5217695\n",
      "0.3890187\n",
      "0.3890187\n",
      "0.40815467\n",
      "0.40815467\n",
      "0.48769054\n",
      "0.48769054\n",
      "0.4285502\n",
      "0.4285502\n",
      "('Philip', 10)\n",
      "0.35333008\n",
      "0.35333008\n",
      "0.37655377\n",
      "0.37655377\n",
      "0.41289133\n",
      "0.41289133\n",
      "0.37393722\n",
      "0.37393722\n",
      "0.45597982\n",
      "0.45597982\n",
      "0.39723596\n",
      "0.39723596\n",
      "0.36178523\n",
      "0.36178523\n",
      "0.34382063\n",
      "0.34382063\n",
      "0.36993274\n",
      "0.36993274\n",
      "0.36925584\n",
      "0.36925584\n",
      "('Philip', 10)\n"
     ]
    }
   ],
   "source": [
    "RC.Attendanceloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "588cad54-3cf9-47e5-9bb3-2ea8953a3f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name Philip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n",
      "Not enough eyes detected for rotation.\n"
     ]
    }
   ],
   "source": [
    "RC.SavetoDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c4e55-ade4-4c07-8adc-9031a1248cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593a877-1f06-4e1f-888c-b1e16256aa54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
